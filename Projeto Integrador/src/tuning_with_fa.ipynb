{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Objetivo do notebook é aplicar os conceitos apresentados no paper \"Mean–variance portfolio optimization using machine learning-based\", de Wei Chen et. all.\r\n",
    "\r\n",
    "## [Link](https://sci-hub.se/10.1016/j.asoc.2020.106943 \"Artigo\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from fa import *\r\n",
    "from tunning import *\r\n",
    "import time\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import datetime as dt\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib import style\r\n",
    "import yfinance as yf\r\n",
    "from sklearn.model_selection import TimeSeriesSplit\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.metrics import mean_absolute_error\r\n",
    "from xgboost import plot_importance\r\n",
    "#from fa import *\r\n",
    "style.use('ggplot')\r\n",
    "\r\n",
    "from sklearn.model_selection import  GridSearchCV\r\n",
    "\r\n",
    "import xgboost as xgb\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(action='ignore')\r\n",
    "\r\n",
    "\r\n",
    "# explicitly require this experimental feature\r\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\r\n",
    "# now you can import normally from model_selection\r\n",
    "from sklearn.model_selection import HalvingGridSearchCV\r\n",
    "\r\n",
    "\r\n",
    "#from stldecompose import decompose\r\n",
    "\r\n",
    "# Chart drawing\r\n",
    "import plotly.io as pio\r\n",
    "import plotly.graph_objects as go\r\n",
    "from plotly.subplots import make_subplots\r\n",
    "from plotly.offline import  init_notebook_mode\r\n",
    "\r\n",
    "# Mute sklearn warnings\r\n",
    "from warnings import simplefilter\r\n",
    "simplefilter(action='ignore', category=FutureWarning)\r\n",
    "simplefilter(action='ignore', category=DeprecationWarning)\r\n",
    "\r\n",
    "# Show charts when running kernel\r\n",
    "init_notebook_mode(connected=True)\r\n",
    "\r\n",
    "# Change default background color for all visualizations\r\n",
    "layout=go.Layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(250,250,250,0.8)')\r\n",
    "fig = go.Figure(layout=layout)\r\n",
    "templated_fig = pio.to_templated(fig)\r\n",
    "pio.templates['my_template'] = templated_fig.layout.template\r\n",
    "pio.templates.default = 'my_template'\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.3.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:29:22.508739Z",
     "iopub.status.busy": "2021-08-15T23:29:22.508739Z",
     "iopub.status.idle": "2021-08-15T23:29:22.576195Z",
     "shell.execute_reply": "2021-08-15T23:29:22.575699Z",
     "shell.execute_reply.started": "2021-08-15T23:29:22.508739Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "my_path = \"C:\\\\Users\\\\victo\\\\Documents\\\\Digital House DS\\\\projetoIntegrador\\\\Projeto Integrador\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pega o dataset de ativos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "df_ativos = pd.read_csv(my_path+\"\\\\data\\\\processed\\\\ativos_paper_com_lag.csv\")\r\n",
    "df_ativos = df_ativos.rename(columns={\"Unnamed: 0\":\"Date\"})\r\n",
    "df_ativos.set_index(\"Date\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                Open      High       Low     Close  Adj Close     Volume  \\\n",
       "Date                                                                       \n",
       "2009-11-02  8.772292  9.632970  8.722638  9.504696   6.291415  265173584   \n",
       "2009-11-03  9.517110  9.661935  9.475731  9.587453   6.346194  207655706   \n",
       "2009-11-04  9.562626  9.968138  9.521247  9.794347   6.483143  235029795   \n",
       "2009-11-05  9.757106  9.889518  9.670211  9.744693   6.450275  126982654   \n",
       "2009-11-06  9.848140  9.992965  9.724003  9.777796   6.472187  154066548   \n",
       "...              ...       ...       ...       ...        ...        ...   \n",
       "2019-11-25  3.610000  3.660000  3.610000  3.650000   3.256570   85133202   \n",
       "2019-11-26  3.660000  3.680000  3.640000  3.670000   3.274414  149997057   \n",
       "2019-11-27  3.670000  3.670000  3.650000  3.660000   3.265492   47606200   \n",
       "2019-11-28  3.660000  3.660000  3.640000  3.650000   3.256570   52741532   \n",
       "2019-11-29  3.650000  3.650000  3.620000  3.630000   3.238726   80189816   \n",
       "\n",
       "                Ativo  1: ln(C/C-1)  2: ln(C-1/C-2)  3: ln(C-2/C-3)  ...  \\\n",
       "Date                                                                 ...   \n",
       "2009-11-02  600000.SS           NaN             NaN             NaN  ...   \n",
       "2009-11-03  600000.SS      0.008669             NaN             NaN  ...   \n",
       "2009-11-04  600000.SS      0.021350        0.008669             NaN  ...   \n",
       "2009-11-05  600000.SS     -0.005083        0.021350        0.008669  ...   \n",
       "2009-11-06  600000.SS      0.003391       -0.005083        0.021350  ...   \n",
       "...               ...           ...             ...             ...  ...   \n",
       "2019-11-25  601988.SS      0.011019       -0.005525        0.002759  ...   \n",
       "2019-11-26  601988.SS      0.005464        0.011019       -0.005525  ...   \n",
       "2019-11-27  601988.SS     -0.002729        0.005464        0.011019  ...   \n",
       "2019-11-28  601988.SS     -0.002736       -0.002729        0.005464  ...   \n",
       "2019-11-29  601988.SS     -0.005495       -0.002736       -0.002729  ...   \n",
       "\n",
       "            10: ln(H-2/O-2)  11: ln(H-3/O-3)  12: ln(L/O)  13: ln(L-1/O-1)  \\\n",
       "Date                                                                         \n",
       "2009-11-02              NaN              NaN    -0.005676              NaN   \n",
       "2009-11-03              NaN              NaN    -0.004357        -0.005676   \n",
       "2009-11-04         0.093593              NaN    -0.004337        -0.004357   \n",
       "2009-11-05         0.015103         0.093593    -0.008946        -0.004337   \n",
       "2009-11-06         0.041531         0.015103    -0.012685        -0.008946   \n",
       "...                     ...              ...          ...              ...   \n",
       "2019-11-25         0.002759         0.002759     0.000000        -0.005525   \n",
       "2019-11-26         0.002751         0.002759    -0.005479         0.000000   \n",
       "2019-11-27         0.013755         0.002751    -0.005464        -0.005479   \n",
       "2019-11-28         0.005450         0.013755    -0.005479        -0.005464   \n",
       "2019-11-29         0.000000         0.005450    -0.008253        -0.005479   \n",
       "\n",
       "            14: ln(L-2/O-2)  15: ln(L-3/O-3)  16: True Range  17: ATR 14d  \\\n",
       "Date                                                                        \n",
       "2009-11-02              NaN              NaN        0.910332          NaN   \n",
       "2009-11-03              NaN              NaN        0.186204          NaN   \n",
       "2009-11-04        -0.005676              NaN        0.446891          NaN   \n",
       "2009-11-05        -0.004357        -0.005676        0.219307          NaN   \n",
       "2009-11-06        -0.004337        -0.004357        0.268962          NaN   \n",
       "...                     ...              ...             ...          ...   \n",
       "2019-11-25        -0.005540         0.000000        0.050000     0.036429   \n",
       "2019-11-26        -0.005525        -0.005540        0.040000     0.035714   \n",
       "2019-11-27         0.000000        -0.005525        0.020000     0.035000   \n",
       "2019-11-28        -0.005479         0.000000        0.020000     0.031429   \n",
       "2019-11-29        -0.005464        -0.005479        0.030000     0.030714   \n",
       "\n",
       "            18: MI 10d  19: RSI 14d  \n",
       "Date                                 \n",
       "2009-11-02         NaN          NaN  \n",
       "2009-11-03         NaN          NaN  \n",
       "2009-11-04         NaN          NaN  \n",
       "2009-11-05         NaN          NaN  \n",
       "2009-11-06         NaN          NaN  \n",
       "...                ...          ...  \n",
       "2019-11-25        0.01          NaN  \n",
       "2019-11-26        0.01          NaN  \n",
       "2019-11-27        0.01          NaN  \n",
       "2019-11-28        0.03          NaN  \n",
       "2019-11-29        0.02          NaN  \n",
       "\n",
       "[57539 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ativo</th>\n",
       "      <th>1: ln(C/C-1)</th>\n",
       "      <th>2: ln(C-1/C-2)</th>\n",
       "      <th>3: ln(C-2/C-3)</th>\n",
       "      <th>...</th>\n",
       "      <th>10: ln(H-2/O-2)</th>\n",
       "      <th>11: ln(H-3/O-3)</th>\n",
       "      <th>12: ln(L/O)</th>\n",
       "      <th>13: ln(L-1/O-1)</th>\n",
       "      <th>14: ln(L-2/O-2)</th>\n",
       "      <th>15: ln(L-3/O-3)</th>\n",
       "      <th>16: True Range</th>\n",
       "      <th>17: ATR 14d</th>\n",
       "      <th>18: MI 10d</th>\n",
       "      <th>19: RSI 14d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-11-02</th>\n",
       "      <td>8.772292</td>\n",
       "      <td>9.632970</td>\n",
       "      <td>8.722638</td>\n",
       "      <td>9.504696</td>\n",
       "      <td>6.291415</td>\n",
       "      <td>265173584</td>\n",
       "      <td>600000.SS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-03</th>\n",
       "      <td>9.517110</td>\n",
       "      <td>9.661935</td>\n",
       "      <td>9.475731</td>\n",
       "      <td>9.587453</td>\n",
       "      <td>6.346194</td>\n",
       "      <td>207655706</td>\n",
       "      <td>600000.SS</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>-0.005676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-04</th>\n",
       "      <td>9.562626</td>\n",
       "      <td>9.968138</td>\n",
       "      <td>9.521247</td>\n",
       "      <td>9.794347</td>\n",
       "      <td>6.483143</td>\n",
       "      <td>235029795</td>\n",
       "      <td>600000.SS</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004337</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>-0.005676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-05</th>\n",
       "      <td>9.757106</td>\n",
       "      <td>9.889518</td>\n",
       "      <td>9.670211</td>\n",
       "      <td>9.744693</td>\n",
       "      <td>6.450275</td>\n",
       "      <td>126982654</td>\n",
       "      <td>600000.SS</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015103</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>-0.008946</td>\n",
       "      <td>-0.004337</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>-0.005676</td>\n",
       "      <td>0.219307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-06</th>\n",
       "      <td>9.848140</td>\n",
       "      <td>9.992965</td>\n",
       "      <td>9.724003</td>\n",
       "      <td>9.777796</td>\n",
       "      <td>6.472187</td>\n",
       "      <td>154066548</td>\n",
       "      <td>600000.SS</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041531</td>\n",
       "      <td>0.015103</td>\n",
       "      <td>-0.012685</td>\n",
       "      <td>-0.008946</td>\n",
       "      <td>-0.004337</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>0.268962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25</th>\n",
       "      <td>3.610000</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>3.610000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.256570</td>\n",
       "      <td>85133202</td>\n",
       "      <td>601988.SS</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>-0.005540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.036429</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26</th>\n",
       "      <td>3.660000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.274414</td>\n",
       "      <td>149997057</td>\n",
       "      <td>601988.SS</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>-0.005540</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27</th>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>3.265492</td>\n",
       "      <td>47606200</td>\n",
       "      <td>601988.SS</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>-0.005464</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28</th>\n",
       "      <td>3.660000</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.256570</td>\n",
       "      <td>52741532</td>\n",
       "      <td>601988.SS</td>\n",
       "      <td>-0.002736</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>-0.005464</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29</th>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.238726</td>\n",
       "      <td>80189816</td>\n",
       "      <td>601988.SS</td>\n",
       "      <td>-0.005495</td>\n",
       "      <td>-0.002736</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>-0.008253</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>-0.005464</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030714</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57539 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "def relative_strength_idx(close, n=14):\r\n",
    "    delta = close.diff()\r\n",
    "    pricesUp = delta.copy()\r\n",
    "    pricesDown = delta.copy()\r\n",
    "    pricesUp[pricesUp < 0] = 0\r\n",
    "    pricesDown[pricesDown > 0] = 0\r\n",
    "    rollUp = pricesUp.rolling(n).mean()\r\n",
    "    rollDown = pricesDown.abs().rolling(n).mean()\r\n",
    "    rs = rollUp / rollDown\r\n",
    "    rsi = 100 - (100 / (1 + rs))\r\n",
    "    return rsi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_ativos(df, ativo):\r\n",
    "    df = df[df['Ativo'] == ativo]\r\n",
    "    df['19: RSI 14d'] = relative_strength_idx(df['Close'])\r\n",
    "    df['Close'] = df.loc[:,'Close'].shift(-1)\r\n",
    "    #Gera um NA, então vamos ter que dropar novamente...\r\n",
    "    df.dropna(inplace=True)\r\n",
    "    list_drop = ['Open', 'High', 'Low', 'Adj Close', 'Volume',\t'Ativo','Date']\r\n",
    "    df = df.drop(columns = list_drop)\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:29:42.248648Z",
     "iopub.status.busy": "2021-08-15T23:29:42.248153Z",
     "iopub.status.idle": "2021-08-15T23:29:42.412824Z",
     "shell.execute_reply": "2021-08-15T23:29:42.412328Z",
     "shell.execute_reply.started": "2021-08-15T23:29:42.248648Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "ativo = '600000.SS'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\r\n",
    "#Setup inital parameters\r\n",
    "\r\n",
    "best_param = {\r\n",
    "\"learning_rate\" : 0.1,\r\n",
    "\"n_estimator\" : 1000,\r\n",
    "\"max_depth\" : 5,\r\n",
    "\"min_child_weight\" : 1,\r\n",
    "\"gamma\" : 0,\r\n",
    "\"colsample_bytree\" : 0.8,\r\n",
    "\"subsample\" : 0.8,\r\n",
    "\"objective\" : 'reg:squarederror',\r\n",
    "\"reg_lambda\":0,\r\n",
    "\"reg_alpha\":0.5,\r\n",
    "\"nthread\" : 4,\r\n",
    "\"seed\" : 248\r\n",
    "}\r\n",
    "\r\n",
    "def get_new_xgboost():\r\n",
    "    return xgb.XGBRegressor(\r\n",
    "         learning_rate = best_param['learning_rate'],\r\n",
    "         n_estimators= best_param['n_estimator'],\r\n",
    "         max_depth= best_param['max_depth'],\r\n",
    "         min_child_weight= best_param['min_child_weight'],\r\n",
    "         gamma= best_param['gamma'],\r\n",
    "         colsample_bytree= best_param['colsample_bytree'],\r\n",
    "         subsample = best_param['subsample'],\r\n",
    "         objective= best_param['objective'],\r\n",
    "         reg_alpha = best_param['reg_alpha'],\r\n",
    "         reg_lambda = best_param['reg_lambda'],\r\n",
    "         nthread= best_param['nthread'],\r\n",
    "         seed= 248)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def update_best_param(new_param):\r\n",
    "    for key, value in new_param.items():\r\n",
    "        best_param[key] = new_param[key]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Análise de Tunning dos modelos do Ativo 600000"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definindo uma função para rodar modelo, mostrar resultados e plotar feature importance, além de armazenar tudo num DF:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "cols_params=['learning_rate', 'n_estimators', 'max_depth', 'min_child_weight', 'gamma', 'subsample', 'colsample_bytree', 'reg_alpha', 'reg_lambda'] \r\n",
    "cols_results = ['MAPE_train', 'MAPE_test', 'MSE_train', 'MSE_test', 'MAE_train', 'MAE_test', 'RMSE_train', 'RMSE_test','tunning_method', 'time', 'n_folds']\r\n",
    "cols_params.extend(cols_results)\r\n",
    "df_model = pd.DataFrame(columns = cols_params)\r\n",
    "df_model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [learning_rate, n_estimators, max_depth, min_child_weight, gamma, subsample, colsample_bytree, reg_alpha, reg_lambda, MAPE_train, MAPE_test, MSE_train, MSE_test, MAE_train, MAE_test, RMSE_train, RMSE_test, tunning_method, time, n_folds]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>MSE_test</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>tunning_method</th>\n",
       "      <th>time</th>\n",
       "      <th>n_folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:30:57.187750Z",
     "iopub.status.busy": "2021-08-15T23:30:57.187750Z",
     "iopub.status.idle": "2021-08-15T23:30:57.201638Z",
     "shell.execute_reply": "2021-08-15T23:30:57.201142Z",
     "shell.execute_reply.started": "2021-08-15T23:30:57.187750Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Créditos: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\r\n",
    "\r\n",
    "def model_fit(estimator, dtrain, dtest, features, target, dmodel, cv_folds=10, early_stopping_rounds=50, tunning_method = 'None'):\r\n",
    "    \r\n",
    "    xgb_param = estimator.get_xgb_params()\r\n",
    "    \r\n",
    "    xgtrain = xgb.DMatrix(data = dtrain[features].values, label = dtrain[target].values)\r\n",
    "    \r\n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round = estimator.get_params()['n_estimators'], nfold = cv_folds,\r\n",
    "                      metrics ='rmse', early_stopping_rounds = early_stopping_rounds, verbose_eval = True)\r\n",
    "    \r\n",
    "    estimator.set_params(n_estimators=cvresult.shape[0])\r\n",
    "    \r\n",
    "  \r\n",
    "        \r\n",
    "    \r\n",
    "    #Fit the algorithm on the data\r\n",
    "    \r\n",
    "    estimator.fit(dtrain[features], dtrain[target], eval_metric='rmse')\r\n",
    "        \r\n",
    "    #Predict training set:\r\n",
    "    dtrain_predictions = estimator.predict(dtrain[features])\r\n",
    "    \r\n",
    "        \r\n",
    "    #Printar resultados no treino:\r\n",
    "    print (\"\\nResultados do modelo no treino\")\r\n",
    "    #print (\"Accuracy : %.4g\" % metrics.accuracy_score(df_train['Disbursed'].values, df_train_predictions))\r\n",
    "    \r\n",
    "    #MAPE = mean_absolute_percentage_error(y_true = y_train['Close'], y_pred = y_pred_test) -> Fazer na mão grande\r\n",
    "    MAPE_train = np.mean(np.abs((dtrain[target].values - dtrain_predictions)/dtrain[target].values))\r\n",
    "    MSE_train = mean_squared_error(y_true = dtrain[target].values, y_pred = dtrain_predictions, squared = False)\r\n",
    "    MAE_train = mean_absolute_error(y_true = dtrain[target].values, y_pred = dtrain_predictions)\r\n",
    "    RMSE_train = mean_squared_error(y_true = dtrain[target].values, y_pred = dtrain_predictions, squared = True)\r\n",
    "    \r\n",
    "    print(f'MAPE = {MAPE_train:.4f}')\r\n",
    "    print(f'MSE = {MSE_train:.4f}')\r\n",
    "    print(f'MAE = {MAE_train:.4f}')\r\n",
    "    print(f'RMSE = {RMSE_train:.4f}')\r\n",
    "    \r\n",
    "    \r\n",
    "    #Prever e printar resultados no teste:\r\n",
    "    \r\n",
    "    dtest_predictions = estimator.predict(dtest[features])\r\n",
    "    \r\n",
    "    #MAPE = mean_absolute_percentage_error(y_true = y_train['Close'], y_pred = y_pred_test) -> Fazer na mão grande\r\n",
    "    MAPE_test = np.mean(np.abs((dtest[target].values - dtest_predictions)/dtest[target].values))\r\n",
    "    MSE_test = mean_squared_error(y_true = dtest[target].values, y_pred = dtest_predictions, squared = False)\r\n",
    "    MAE_test = mean_absolute_error(y_true = dtest[target].values, y_pred = dtest_predictions)\r\n",
    "    RMSE_test = mean_squared_error(y_true = dtest[target].values, y_pred = dtest_predictions, squared = True)\r\n",
    "\r\n",
    "    print (\"\\nResultados do modelo no teste\")\r\n",
    "    print(f'MAPE = {MAPE_test:.4f}')\r\n",
    "    print(f'MSE = {MSE_test:.4f}')\r\n",
    "    print(f'MAE = {MAE_test:.4f}')\r\n",
    "    print(f'RMSE = {RMSE_test:.4f}')\r\n",
    "    \r\n",
    "   \r\n",
    "    \r\n",
    "    #Plotar gráfico treino e teste:\r\n",
    "    \r\n",
    "    print (\"\\n\")\r\n",
    "    print (\"Time Series de treino e teste:\")\r\n",
    "\r\n",
    "    plt.rcParams[\"figure.figsize\"] = (100, 20)\r\n",
    "    fig = make_subplots(rows=3, cols=1, )\r\n",
    "\r\n",
    "    fig.add_trace(go.Scatter(x = dtrain.index, y = dtrain[target].values,\r\n",
    "                             name='Real - Treino',\r\n",
    "                             marker_color='Green'), row=1, col=1)\r\n",
    "\r\n",
    "    fig.add_trace(go.Scatter(x = dtrain.index,\r\n",
    "                             y = dtrain_predictions,\r\n",
    "                             name='Predição - Treino',\r\n",
    "                             marker_color='DarkBlue'), row=1, col=1)\r\n",
    "\r\n",
    "    fig.add_trace(go.Scatter(x = dtest.index, y = dtest[target].values,\r\n",
    "                             name='Real - Teste',\r\n",
    "                             marker_color='Green'), row=3, col=1)\r\n",
    "\r\n",
    "    fig.add_trace(go.Scatter(x = dtest.index,\r\n",
    "                             y = dtest_predictions,\r\n",
    "                             name='Predição - Teste',\r\n",
    "                             marker_color='DarkBlue'), row=3, col=1)\r\n",
    "\r\n",
    "    fig.show()\r\n",
    "    \r\n",
    "     \r\n",
    "    #Plotar feature importance:\r\n",
    "    \r\n",
    "    print (\"\\n\")\r\n",
    "    plt.rcParams[\"figure.figsize\"] = (20, 10)\r\n",
    "    plot_importance(estimator, height = 0.5)\r\n",
    "    \r\n",
    "    #Armazenando os parâmetros e resultados em um DF:\r\n",
    "    \r\n",
    "    params_results = []\r\n",
    "    \r\n",
    "    cols_params=['learning_rate', 'n_estimators', 'max_depth', 'min_child_weight', 'gamma', 'subsample', 'colsample_bytree', 'reg_alpha', 'reg_lambda'] \r\n",
    "    \r\n",
    "    for i in range(len(cols_params)):\r\n",
    "        params_results.append(estimator.get_params()[cols_params[i]])\r\n",
    "    \r\n",
    "    params_results.extend([MAPE_train, MAPE_test, MSE_train, MSE_test, MAE_train, MAE_test, RMSE_train, RMSE_test, tunning_method])\r\n",
    "    \r\n",
    "    dmodel.loc[len(dmodel)] = params_results\r\n",
    "    print (\"DataFrame consolidado de parâmetros e resultados tentados até aqui:\")\r\n",
    "    \r\n",
    "    return dmodel\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Créditos: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\r\n",
    "\r\n",
    "def model_fit_xgboost(time, tunning_method = 'None'):\r\n",
    "    cv_folds=5 \r\n",
    "    early_stopping_rounds=50\r\n",
    "    features = X_train.columns\r\n",
    "    target = 'Close'\r\n",
    "    estimator = get_new_xgboost()\r\n",
    "    xgb_param = estimator.get_xgb_params()\r\n",
    "    \r\n",
    "    xgtrain = xgb.DMatrix(data = dtrain[features].values, label = dtrain[target].values)\r\n",
    "    \r\n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round = estimator.get_params()['n_estimators'], nfold = cv_folds,\r\n",
    "                      metrics ='rmse', early_stopping_rounds = early_stopping_rounds, verbose_eval = True)\r\n",
    "    \r\n",
    "    estimator.set_params(n_estimators=cvresult.shape[0])\r\n",
    "    print(\"Model Fit XGBoost estimator param:{}\".format(estimator.get_xgb_params()))\r\n",
    "  \r\n",
    "        \r\n",
    "    \r\n",
    "    #Fit the algorithm on the data\r\n",
    "    \r\n",
    "    estimator.fit(dtrain[features], dtrain[target], eval_metric='rmse')\r\n",
    "        \r\n",
    "    #Predict training set:\r\n",
    "    dtrain_predictions = estimator.predict(dtrain[features])\r\n",
    "    \r\n",
    "        \r\n",
    "    #Printar resultados no treino:\r\n",
    "    print (\"\\nResultados do modelo no treino\")\r\n",
    "    #print (\"Accuracy : %.4g\" % metrics.accuracy_score(df_train['Disbursed'].values, df_train_predictions))\r\n",
    "    \r\n",
    "    #MAPE = mean_absolute_percentage_error(y_true = y_train['Close'], y_pred = y_pred_test) -> Fazer na mão grande\r\n",
    "    MAPE_train = np.mean(np.abs((dtrain[target].values - dtrain_predictions)/dtrain[target].values))\r\n",
    "    MSE_train = mean_squared_error(y_true = dtrain[target].values, y_pred = dtrain_predictions, squared = False)\r\n",
    "    MAE_train = mean_absolute_error(y_true = dtrain[target].values, y_pred = dtrain_predictions)\r\n",
    "    RMSE_train = mean_squared_error(y_true = dtrain[target].values, y_pred = dtrain_predictions, squared = True)\r\n",
    "    \r\n",
    "    #print(f'MAPE = {MAPE_train:.4f}')\r\n",
    "    #print(f'MSE = {MSE_train:.4f}')\r\n",
    "    #print(f'MAE = {MAE_train:.4f}')\r\n",
    "    #print(f'RMSE = {RMSE_train:.4f}')\r\n",
    "    \r\n",
    "    \r\n",
    "    #Prever e printar resultados no teste:\r\n",
    "    \r\n",
    "    dtest_predictions = estimator.predict(dtest[features])\r\n",
    "    \r\n",
    "    #MAPE = mean_absolute_percentage_error(y_true = y_train['Close'], y_pred = y_pred_test) -> Fazer na mão grande\r\n",
    "    MAPE_test = np.mean(np.abs((dtest[target].values - dtest_predictions)/dtest[target].values))\r\n",
    "    MSE_test = mean_squared_error(y_true = dtest[target].values, y_pred = dtest_predictions, squared = False)\r\n",
    "    MAE_test = mean_absolute_error(y_true = dtest[target].values, y_pred = dtest_predictions)\r\n",
    "    RMSE_test = mean_squared_error(y_true = dtest[target].values, y_pred = dtest_predictions, squared = True)\r\n",
    "\r\n",
    "    #print (\"\\nResultados do modelo no teste\")\r\n",
    "    ##print(f'MAPE = {MAPE_test:.4f}')\r\n",
    "    #print(f'MSE = {MSE_test:.4f}')\r\n",
    "    #print(f'MAE = {MAE_test:.4f}')\r\n",
    "    #print(f'RMSE = {RMSE_test:.4f}')\r\n",
    "    \r\n",
    "   \r\n",
    "    \r\n",
    "    #Plotar gráfico treino e teste:\r\n",
    "    \r\n",
    "    print (\"\\n\")\r\n",
    "    print (\"Time Series de treino e teste:\")\r\n",
    "\r\n",
    "    plt.rcParams[\"figure.figsize\"] = (100, 20)\r\n",
    "    fig = make_subplots(rows=3, cols=1, )\r\n",
    "\r\n",
    "    fig.add_trace(go.Scatter(x = dtrain.index, y = dtrain[target].values,\r\n",
    "                             name='Real - Treino',\r\n",
    "                             marker_color='Green'), row=1, col=1)\r\n",
    "\r\n",
    "    fig.add_trace(go.Scatter(x = dtrain.index,\r\n",
    "                             y = dtrain_predictions,\r\n",
    "                             name='Predição - Treino',\r\n",
    "                             marker_color='DarkBlue'), row=1, col=1)\r\n",
    "\r\n",
    "    fig.add_trace(go.Scatter(x = dtest.index, y = dtest[target].values,\r\n",
    "                             name='Real - Teste',\r\n",
    "                             marker_color='Green'), row=3, col=1)\r\n",
    "\r\n",
    "    fig.add_trace(go.Scatter(x = dtest.index,\r\n",
    "                             y = dtest_predictions,\r\n",
    "                             name='Predição - Teste',\r\n",
    "                             marker_color='DarkBlue'), row=3, col=1)\r\n",
    "\r\n",
    "    fig.show()\r\n",
    "    \r\n",
    "     \r\n",
    "    #Plotar feature importance:\r\n",
    "    \r\n",
    "    print (\"\\n\")\r\n",
    "    plt.rcParams[\"figure.figsize\"] = (20, 10)\r\n",
    "    plot_importance(estimator, height = 0.5)\r\n",
    "    \r\n",
    "    #Armazenando os parâmetros e resultados em um DF:\r\n",
    "    \r\n",
    "    params_results = []\r\n",
    "    \r\n",
    "    cols_params=['learning_rate', 'n_estimators', 'max_depth', 'min_child_weight', 'gamma', 'subsample', 'colsample_bytree', 'reg_alpha', 'reg_lambda'] \r\n",
    "    \r\n",
    "    for i in range(len(cols_params)):\r\n",
    "        params_results.append(estimator.get_params()[cols_params[i]])\r\n",
    "    \r\n",
    "    params_results.extend([MAPE_train, MAPE_test, MSE_train, MSE_test, MAE_train, MAE_test, RMSE_train, RMSE_test, tunning_method, time, cv_folds])\r\n",
    "    \r\n",
    "    df_model.loc[len(df_model)] = params_results\r\n",
    "    print (\"DataFrame consolidado de parâmetros e resultados tentados até aqui:\")\r\n",
    "    \r\n",
    "    return df_model\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:30:57.202630Z",
     "iopub.status.busy": "2021-08-15T23:30:57.202630Z",
     "iopub.status.idle": "2021-08-15T23:30:57.232390Z",
     "shell.execute_reply": "2021-08-15T23:30:57.231894Z",
     "shell.execute_reply.started": "2021-08-15T23:30:57.202630Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def find_best_paramater(xgboost_estimator, param_test, X_train, y_train ):\r\n",
    "    halvingGrid = HalvingGridSearchCV(estimator = xgboost_estimator, param_grid = param_test, n_jobs=-1, cv=TimeSeriesSplit(), verbose=2)\r\n",
    "    halvingGrid.fit(X_train, y_train)\r\n",
    "    print(\"Best Params{}\\nFinalParam{}\\nBestScore:{}\".format(halvingGrid.cv_results_['params'], halvingGrid.best_params_, halvingGrid.best_score_))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def get_gridSearch_best_param(xgboost_estimator, param_test):\r\n",
    "    gsearch = GridSearchCV(estimator = xgboost_estimator, \r\n",
    "                         param_grid = param_test, n_jobs= -1, cv=TimeSeriesSplit(n_splits=3), verbose=2)\r\n",
    "\r\n",
    "    gsearch.fit(X_train, y_train)\r\n",
    "    gsearch.cv_results_['params'], gsearch.best_params_, gsearch.best_score_\r\n",
    "    return gsearch.best_params_\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def get_halvingSearch_best_param(estimator, param_test):\r\n",
    "    halvingGrid = HalvingGridSearchCV(estimator = estimator, param_grid = param_test, n_jobs=-1, cv=TimeSeriesSplit(n_splits=3), verbose=2)\r\n",
    "    halvingGrid.fit(X_train, y_train)\r\n",
    "    halvingGrid.cv_results_['params'], halvingGrid.best_params_\r\n",
    "    return halvingGrid.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "df = get_ativos(df_ativos, ativo)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "test_size = 0.2\r\n",
    "test_split_idx  = int(df.shape[0] * (1-test_size))\r\n",
    "dtrain  = df.iloc[:test_split_idx].copy()\r\n",
    "dtest   = df.iloc[test_split_idx+1:].copy()\r\n",
    "X_train = dtrain.drop(columns=['Close'])\r\n",
    "y_train = dtrain['Close']\r\n",
    "X_test = dtest.drop(columns=['Close'])\r\n",
    "y_test = dtest['Close']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Fix learning rate (aka \"eta\") and number of estimators for tuning tree-based parameters"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Vamos setar learning_rate para 0.1 e n_etimators para 1000. A ideia é tunar apenas os parâmetros específicos de árvores, que vão começar como segue:\r\n",
    "\r\n",
    "xgb1 = get_new_xgboost()\r\n",
    "\r\n",
    "model_fit(estimator = xgb1, dtrain = dtrain, dtest = dtest, features = X_train.columns, target = 'Close', dmodel = df_model, cv_folds=5, early_stopping_rounds=50)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:30:57.233879Z",
     "iopub.status.busy": "2021-08-15T23:30:57.233879Z",
     "iopub.status.idle": "2021-08-15T23:31:05.796817Z",
     "shell.execute_reply": "2021-08-15T23:31:05.796320Z",
     "shell.execute_reply.started": "2021-08-15T23:30:57.233879Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como o erro continuou caindo até o 368º estimador, vamos atribuir esse valor a n_estimator. Percebemos que há claramente um overfitting quando observamos a série temporal de treino."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Tune max_depth and min_child_weight\r\n",
    "We tune these first as they will have the highest impact on model outcome. To start with, let’s set wider ranges and then we will perform another iteration for smaller ranges."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test1 = {\r\n",
    " 'max_depth':range(1,15,2),\r\n",
    " 'min_child_weight':range(1,10,2)\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:31:05.798305Z",
     "iopub.status.busy": "2021-08-15T23:31:05.797808Z",
     "iopub.status.idle": "2021-08-15T23:31:43.899015Z",
     "shell.execute_reply": "2021-08-15T23:31:43.898022Z",
     "shell.execute_reply.started": "2021-08-15T23:31:05.798305Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_gridSearch_best_param(get_new_xgboost(), param_test1)\r\n",
    "update_best_param({'max_depth': 3, 'min_child_weight': 9})\r\n",
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encontramos os melhores valores. Para aprofundar, vamos aumentar a granularidade do teste variando os best_params em +1 e -1."
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test2 = {\r\n",
    " 'max_depth':[1, 2, 3,4,5],\r\n",
    " 'min_child_weight':[1, 2, 3,4,5]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = get_gridSearch_best_param(get_new_xgboost(), param_test2)\r\n",
    "update_best_param(result)\r\n",
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Permanecemos com os valores encontrados como os melhores parâmetros."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Tune gamma\r\n",
    "Now lets tune gamma value using the parameters already tuned above. Gamma can take various values but I’ll check for 5 values here. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test3 = {\r\n",
    " 'gamma':[i/10 for i in range(0,10)]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = get_gridSearch_best_param(get_new_xgboost(), param_test3)\r\n",
    "update_best_param(result)\r\n",
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "gamma = 0.0 se mostrou um bom valor. Agora que fizemos esse passo, é importante reavaliar o n_estimators. Vamos lá:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"n_estimators\" deve continumar com o valor 368, já que o aumento da quantidade de árvores não se justifica pela diminuição no erro."
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Tune subsample and colsample_bytree\n",
    "The next step would be try different subsample and colsample_bytree values. Lets do this in 2 stages as well and take values 0.6,0.7,0.8,0.9 for both to start with."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test4 = {\r\n",
    " 'subsample':[i/10 for i in range(6,10)],\r\n",
    " 'colsample_bytree':[i/10 for i in range(6,10)]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = get_gridSearch_best_param(get_new_xgboost(), param_test4)\r\n",
    "update_best_param(result)\r\n",
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:32:45.635102Z",
     "iopub.status.busy": "2021-08-15T23:32:45.635102Z",
     "iopub.status.idle": "2021-08-15T23:33:25.872579Z",
     "shell.execute_reply": "2021-08-15T23:33:25.871587Z",
     "shell.execute_reply.started": "2021-08-15T23:32:45.635102Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora que encontramos os melhores valores, vamos aumentar a granularidade para 0.05 e observar:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test4 = {\r\n",
    " 'subsample':[i/100 for i in range(75,90,5)],\r\n",
    " 'colsample_bytree':[i/100 for i in range(85,100,5)]\r\n",
    "}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = get_gridSearch_best_param(get_new_xgboost(), param_test4)\r\n",
    "update_best_param(result)\r\n",
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:33:25.874067Z",
     "iopub.status.busy": "2021-08-15T23:33:25.874067Z",
     "iopub.status.idle": "2021-08-15T23:33:50.181522Z",
     "shell.execute_reply": "2021-08-15T23:33:50.181026Z",
     "shell.execute_reply.started": "2021-08-15T23:33:25.874067Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Valores não se alteraram. Definimos, então:\n",
    "colsample_bytree = 0.9 ;\n",
    "subsample = 0.8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Tuning Regularization Parameters\n",
    "Next step is to apply regularization to reduce overfitting. Though many people don’t use this parameters much as gamma provides a substantial way of controlling complexity. But we should always try it. I’ll tune ‘reg_alpha’ value here and leave it upto you to try different values of ‘reg_lambda’."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test5 = {\r\n",
    " 'reg_alpha':[0, 1e-4, 1e-2, 0.1, 1, 100]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = get_gridSearch_best_param(get_new_xgboost(), param_test5)\r\n",
    "update_best_param(result)\r\n",
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:33:50.183010Z",
     "iopub.status.busy": "2021-08-15T23:33:50.183010Z",
     "iopub.status.idle": "2021-08-15T23:34:07.280119Z",
     "shell.execute_reply": "2021-08-15T23:34:07.279127Z",
     "shell.execute_reply.started": "2021-08-15T23:33:50.183010Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aparentemente, o alpha ideal deve ser pequeno, da ordem de 0.1. Vamos explorar um pouco mais aumentando a granularidade:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test7 = {\r\n",
    " 'reg_alpha':[8e-2, 5e-2, 1e-1, 3e-1, 5e-1]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:34:07.281111Z",
     "iopub.status.busy": "2021-08-15T23:34:07.281111Z",
     "iopub.status.idle": "2021-08-15T23:34:19.703423Z",
     "shell.execute_reply": "2021-08-15T23:34:19.702927Z",
     "shell.execute_reply.started": "2021-08-15T23:34:07.281111Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = get_gridSearch_best_param(get_new_xgboost(), param_test7)\r\n",
    "update_best_param(result)\r\n",
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "reg_alpha = 0.05 confirmou ser o melhor valor.\n",
    "Agora vamos rodar mais uma vez o modelo, dessa vez aumentando o n_estimators para avaliar o número ideal:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ainda bastante overfitado... n_estimators poderia adotar o valor de 534. Vamos checar o reg_lambda."
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T22:46:17.066061Z",
     "iopub.status.busy": "2021-08-08T22:46:17.066061Z",
     "iopub.status.idle": "2021-08-08T22:46:17.077965Z",
     "shell.execute_reply": "2021-08-08T22:46:17.076973Z",
     "shell.execute_reply.started": "2021-08-08T22:46:17.066061Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explorando o reg_lambda:"
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T17:58:02.212285Z",
     "iopub.status.busy": "2021-08-08T17:58:02.212285Z",
     "iopub.status.idle": "2021-08-08T17:58:02.227136Z",
     "shell.execute_reply": "2021-08-08T17:58:02.226663Z",
     "shell.execute_reply.started": "2021-08-08T17:58:02.212285Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test6 = {\r\n",
    " 'reg_lambda':[0, 1e-5, 1e-2, 0.1, 1, 100]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = get_gridSearch_best_param(get_new_xgboost(), param_test6)\r\n",
    "update_best_param(result)\r\n",
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:34:35.203908Z",
     "iopub.status.busy": "2021-08-15T23:34:35.203412Z",
     "iopub.status.idle": "2021-08-15T23:35:01.849011Z",
     "shell.execute_reply": "2021-08-15T23:35:01.848514Z",
     "shell.execute_reply.started": "2021-08-15T23:34:35.203908Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Opa... lambda 100 é o melhor valor até então. Vamos aumentar um pouco mais esse range em torno desse valor, para verificar:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test9 = {\r\n",
    " 'reg_lambda':[90, 100, 500, 1000, 2000, 2500]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test9 = {\r\n",
    " 'reg_lambda':[90, 100, 500, 1000, 2000, 2500]\r\n",
    "}\r\n",
    "result = get_gridSearch_best_param(get_new_xgboost(), param_test9)\r\n",
    "update_best_param(result)\r\n",
    "model_fit_xgboost('GridSearch')"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T23:35:01.850500Z",
     "iopub.status.busy": "2021-08-15T23:35:01.850003Z",
     "iopub.status.idle": "2021-08-15T23:35:25.020651Z",
     "shell.execute_reply": "2021-08-15T23:35:25.020154Z",
     "shell.execute_reply.started": "2021-08-15T23:35:01.850500Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Não faz muito sentido ter um lambda tão alto... Explorar isso depois"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6: Reducing Learning Rate\n",
    "Lastly, we should lower the learning rate and add more trees. Let's use the cv function of XGBoost to do the job again."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = get_gridSearch_best_param(get_new_xgboost(), param_test6)\r\n",
    "update_best_param({\"learning_rate\":0.01})\r\n",
    "model_fit_xgboost('GridSearch')\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-08-15T23:38:59.287699Z",
     "iopub.status.busy": "2021-08-15T23:38:59.287202Z",
     "iopub.status.idle": "2021-08-15T23:39:24.169006Z",
     "shell.execute_reply": "2021-08-15T23:39:24.168511Z",
     "shell.execute_reply.started": "2021-08-15T23:38:59.287699Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing with Halving Grid Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tunning_and_fit(param, tunning_method):\r\n",
    "    start = time.time()\r\n",
    "    result = get_halvingSearch_best_param(get_new_xgboost(), param)\r\n",
    "    end = time.time()\r\n",
    "    update_best_param(result)\r\n",
    "    total_time = end - start\r\n",
    "    return model_fit_xgboost(total_time, tunning_method)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def reset_best_param():\r\n",
    "    best_param = {\r\n",
    "    \"learning_rate\" : 0.1,\r\n",
    "    \"n_estimator\" : 1000,\r\n",
    "    \"max_depth\" : 5,\r\n",
    "    \"min_child_weight\" : 1,\r\n",
    "    \"gamma\" : 0,\r\n",
    "    \"colsample_bytree\" : 0.8,\r\n",
    "    \"subsample\" : 0.8,\r\n",
    "    \"objective\" : 'reg:squarederror',\r\n",
    "    \"nthread\" : 4,\r\n",
    "    \"seed\" : 248\r\n",
    "    }\r\n",
    "    update_best_param(best_param)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reset_best_param()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Max depth and min_child_weight"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test1 = {\r\n",
    " 'max_depth':range(1,15,2),\r\n",
    " 'min_child_weight':range(1,10,2)\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tunning_and_fit(param_test1, 'HalvingGrid Dual Parameter')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune Gamma"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test3 = {\r\n",
    " 'gamma':[i/10 for i in range(0,10)]\r\n",
    "}\r\n",
    "tunning_and_fit(param_test3, 'HalvinGrid Single Parameter')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune subsample and colsampl_bytree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test4 = {\r\n",
    " 'subsample':[i/10 for i in range(6,10)],\r\n",
    " 'colsample_bytree':[i/10 for i in range(6,10)]\r\n",
    "}\r\n",
    "tunning_and_fit(param_test4, 'HalvinGrid Dual Parameter')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune Regularization Param"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test = {\r\n",
    " 'reg_alpha':[8e-2, 5e-2, 1e-1, 3e-1, 5e-1],\r\n",
    " 'reg_lambda':[90, 100, 500, 1000, 2000, 2500]\r\n",
    "}\r\n",
    "tunning_and_fit(param_test, 'HalvinGrid Dual Parameter')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reducing Learning Rate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_test = {\r\n",
    " 'learning_rate':[i/10 for i in range(0,10)]\r\n",
    "}\r\n",
    "tunning_and_fit(param_test, 'HalvinGrid Single Parameter')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get All Parameter at once"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reset_best_param()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_param ={\r\n",
    "'max_depth':range(1,15,5),\r\n",
    "'min_child_weight':range(1,10,5),\r\n",
    "'gamma':[i/10 for i in range(0,10)],\r\n",
    "'subsample':[i/100 for i in range(75,90,5)],\r\n",
    "'colsample_bytree':[i/100 for i in range(85,100,5)],\r\n",
    "'reg_lambda':[0, 1e-5, 1e-2, 0.1, 1, 100],\r\n",
    "'reg_alpha':[8e-2, 5e-2, 1e-1, 3e-1, 5e-1]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "'subsample':[i/100 for i in range(75,90,5)],\r\n",
    "'colsample_bytree':[i/100 for i in range(85,100,5)],\r\n",
    "'reg_lambda':[0, 1e-5, 1e-2, 0.1, 1, 100],\r\n",
    "'reg_alpha':[0, 1e-4, 1e-2, 0.1, 1, 100]\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tunning_and_fit(all_param, 'HalvinGrid All Parameter')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing FA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fitness Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "df = df.reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3)\r\n",
    "df = df.reset_index(drop=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def Fitness_function(D, fireFly):\r\n",
    "    estimator = xgb.XGBRegressor(\r\n",
    "         learning_rate = fireFly[0],\r\n",
    "         max_depth= int(fireFly[1]),\r\n",
    "         min_child_weight= fireFly[2],\r\n",
    "         gamma= fireFly[3],\r\n",
    "         colsample_bytree= fireFly[4],\r\n",
    "         subsample = fireFly[5],\r\n",
    "         reg_alpha = fireFly[6],\r\n",
    "         reg_lambda = fireFly[7],\r\n",
    "         seed= 248)\r\n",
    "    n_fold = 5\r\n",
    "    tscv = TimeSeriesSplit(n_splits=n_fold)\r\n",
    "    mape = 0\r\n",
    "    for train_index, test_index in tscv.split(df):\r\n",
    "        new_x_train = df.loc[train_index].drop(columns=['Close'])\r\n",
    "        new_y_train = df.loc[train_index]['Close']\r\n",
    "\r\n",
    "        new_x_test = df.loc[test_index].drop(columns=['Close'])\r\n",
    "        new_y_test = df.loc[test_index]['Close']\r\n",
    "\r\n",
    "        estimator.fit(new_x_train, new_y_train, eval_metric='rmse')\r\n",
    "        \r\n",
    "        y_predict = estimator.predict(new_x_test)\r\n",
    "        MAPE_test = np.mean(np.abs((new_y_test.values - y_predict)/new_y_test.values))\r\n",
    "        mape += MAPE_test\r\n",
    "        #print(\"Mape:{}\\n\".format(MAPE_test))\r\n",
    "    #print(\"Final Mape:{}\".format(mape/n_fold))\r\n",
    "    return mape/n_fold\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "parameters = {\r\n",
    "    \"learning_rate\" :[0.3, 0.5],\r\n",
    "    \"max_depth\" : [3, 5],\r\n",
    "    \"min_child_weight\" :[0.5, 10],\r\n",
    "    \"gamma\": [0, 5],\r\n",
    "    \"colsample_bytree\": [0.5, 1],\r\n",
    "    \"subsample\" :[0.8, 1],\r\n",
    "    \"reg_alpha\" : [1e-2, 1],\r\n",
    "    \"reg_lambda\" : [1e-4, 1],\r\n",
    "    \"n_estimator\" : [50, 400],\r\n",
    "}\r\n",
    "\r\n",
    "fa = Tunning_FA(df, 'Close', parameters)\r\n",
    "fa.Run()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ce22d8c72215>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mfa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTunning_FA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Close'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mfa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\victo\\Documents\\Digital House DS\\projetoIntegrador\\Projeto Integrador\\src\\tunning.py\u001b[0m in \u001b[0;36mRun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0malg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNewFireflyAlgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_population\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_interactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbetamin\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower_boundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper_boundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fireflies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\victo\\Documents\\Digital House DS\\projetoIntegrador\\Projeto Integrador\\src\\fa.py\u001b[0m in \u001b[0;36mRun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# evaluate new solutions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFitness\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFireflies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluations\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFitness\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\victo\\Documents\\Digital House DS\\projetoIntegrador\\Projeto Integrador\\src\\tunning.py\u001b[0m in \u001b[0;36mload_initial_fitness_fun\u001b[1;34m(self, D, fireFly)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mnew_y_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_x_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_x_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m    737\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tunning_and_fit_firefly(n_dimension, n_population, n_interactions, alpha, betamin, gamma, lower_boundary, upper_boundary):\r\n",
    "    start = time.time()\r\n",
    "    alg = NewFireflyAlgorithm(n_dimension, n_population, n_interactions, alpha , betamin , gamma , lower_boundary, upper_boundary, Fitness_function)\r\n",
    "    end = time.end()\r\n",
    "    total_time = end - start\r\n",
    "    best_score, best_fireflies, best_index = alg.Run()\r\n",
    "    fireFly = best_fireflies[best_index[0]]\r\n",
    "    new_param = {\r\n",
    "        \"learning_rate\" = fireFly[0],\r\n",
    "        \"max_depth\"= int(fireFly[1]),\r\n",
    "        \"min_child_weight\"= fireFly[2],\r\n",
    "        \"gamma\"= fireFly[3],\r\n",
    "        \"colsample_bytree\"= fireFly[4],\r\n",
    "        \"subsample\" = fireFly[5],\r\n",
    "        \"reg_alpha\" = fireFly[6],\r\n",
    "        \"reg_lambda\" = fireFly[7]\r\n",
    "    }\r\n",
    "    update_best_param(new_param)\r\n",
    "    model_fit_xgboost(total_time, 'FA')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\r\n",
    "lower_boundary = [0.1, 3, 1, 0, 0.8, 0.6, 0, 1e-5]\r\n",
    "upper_boundary = [0.5, 7, 3, 0.1, 1, 1, 1e-3, 5e-2]\r\n",
    "n_dimension = 8\r\n",
    "n_population = 100\r\n",
    "n_interactions = 2000\r\n",
    "alpha = 1\r\n",
    "betamin = 0.2\r\n",
    "\r\n",
    "tunning_and_fit_firefly(n_dimension, n_population, n_interactions, alpha, betamin, gamma, lower_boundary, upper_boundary)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\r\n",
    "lower_boundary = [0.1, 3, 1, 0, 0.8, 0.6, 0, 1e-5]\r\n",
    "upper_boundary = [0.5, 7, 3, 0.1, 1, 1, 1e-3, 5e-2]\r\n",
    "n_dimension = 8\r\n",
    "n_population = 100\r\n",
    "n_interactions = 2000\r\n",
    "alpha = 1\r\n",
    "betamin = 0.4\r\n",
    "gamma = 5.0\r\n",
    "tunning_and_fit_firefly(n_dimension, n_population, n_interactions, alpha, betamin, gamma, lower_boundary, upper_boundary)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lower_boundary =   [0.1, 3, 1, 0, 0.8, 0.6, 0, 1e-5]\r\n",
    "upper_boundary = [0.5, 7, 3, 0.01, 1, 1, 1e-3, 5e-2]\r\n",
    "\r\n",
    "alg = NewFireflyAlgorithm(8, 40, 2000, 0.5, 0.2, 1.0, lower_boundary, upper_boundary, Fitness_function)\r\n",
    "tunning_and_fit_firefly(n_dimension, n_population, n_interactions, alpha, betamin, gamma, lower_boundary, upper_boundary)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "lower_boundary = [0.1, 3, 1, 0, 0.8, 0.6, 0, 1e-5]\r\n",
    "upper_boundary = [0.5, 7, 3, 0.1, 1, 1, 1e-3, 5e-2]\r\n",
    "n_dimension = 8\r\n",
    "n_population = 50\r\n",
    "n_interactions = 6000\r\n",
    "alpha = 0.5\r\n",
    "betamin = 0.2\r\n",
    "gamma = 1.0\r\n",
    "tunning_and_fit_firefly(n_dimension, n_population, n_interactions, alpha, betamin, gamma, lower_boundary, upper_boundary)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}